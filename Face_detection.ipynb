{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a21d7a3",
   "metadata": {},
   "source": [
    "# Face detection In Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00ef234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b5d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('./images/faces.jpg')\n",
    "cv2.imshow('face',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bbeb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier('./model/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6649c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(img):\n",
    "    image=img.copy()\n",
    "    # step 1: convert image to grayscale\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # step 2: apply gray scale to cascade classifier\n",
    "    box,detections=face_cascade.detectMultiScale2(gray,minNeighbors=6)\n",
    "    print(box)\n",
    "    for x,y,w,h in box:\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# The face_cascade.detectMultiScale2() function is used to detect faces in the grayscale image. \n",
    "# It takes the grayscale image as input and uses a cascade classifier previously trained on face detection.\n",
    "# The minNeighbors parameter specifies the number of neighbors a candidate rectangle should have to retain it. \n",
    "# Increasing this value results in fewer detections but with higher quality. \n",
    "# The function returns two values: box and detections. box contains the coordinates and dimensions of the detected faces, \n",
    "# while detections represents the detection confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d099ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[379  49  65  65]\n",
      " [367 316 106 106]\n",
      " [438 218  69  69]\n",
      " [167 224  74  74]\n",
      " [175  55  67  67]]\n"
     ]
    }
   ],
   "source": [
    "img_detect=face_detection(img)\n",
    "cv2.imshow('face_detection',img_detect)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3ba408",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=img.copy()\n",
    "# step 1: convert image to grayscale\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "# step 2: apply gray scale to cascade classifier\n",
    "box,detections=face_cascade.detectMultiScale2(gray,minNeighbors=14)\n",
    "for x,y,w,h in box:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "    \n",
    "cv2.imshow('face_detection1',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd335003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 47, 24, 83, 82])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "947725ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[379,  49,  65,  65],\n",
       "       [367, 316, 106, 106],\n",
       "       [175,  55,  67,  67],\n",
       "       [438, 218,  69,  69],\n",
       "       [167, 224,  74,  74]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860be18",
   "metadata": {},
   "source": [
    "# Realtime Face Detection(Videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a3db05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap= cv2.VideoCapture(0)\n",
    "face_cascade=cv2.CascadeClassifier('./model/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be8e1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[140 324  60  60]\n",
      " [284 217 189 189]]\n",
      "[[283 218 188 188]]\n",
      "[[143 325  55  55]\n",
      " [282 217 191 191]]\n",
      "[[141 324  60  60]\n",
      " [282 217 192 192]]\n",
      "[[138 323  63  63]\n",
      " [280 216 192 192]]\n",
      "[[279 217 193 193]]\n",
      "[[142 325  58  58]\n",
      " [281 219 190 190]]\n",
      "[[140 326  58  58]\n",
      " [280 218 192 192]]\n",
      "[[142 327  56  56]\n",
      " [281 218 191 191]]\n",
      "[[142 327  58  58]\n",
      " [282 219 189 189]]\n",
      "[[281 218 191 191]]\n",
      "[[139 326  60  60]\n",
      " [283 220 188 188]]\n",
      "[[282 218 190 190]]\n",
      "[[282 218 189 189]]\n",
      "[[141 327  57  57]\n",
      " [283 219 188 188]]\n",
      "[[140 326  58  58]\n",
      " [281 218 192 192]]\n",
      "[[140 325  58  58]\n",
      " [280 218 192 192]]\n",
      "[[141 327  57  57]\n",
      " [280 217 193 193]]\n",
      "[[141 325  60  60]\n",
      " [283 218 191 191]]\n",
      "[[283 218 189 189]\n",
      " [141 325  59  59]]\n",
      "[[140 325  60  60]\n",
      " [281 218 191 191]]\n",
      "[[139 324  61  61]\n",
      " [282 217 191 191]]\n",
      "[[282 217 191 191]\n",
      " [141 326  57  57]]\n",
      "[[142 327  56  56]\n",
      " [281 217 192 192]]\n",
      "[[142 326  58  58]\n",
      " [284 219 190 190]]\n",
      "[[142 325  58  58]\n",
      " [291 218 186 186]]\n",
      "[[140 325  59  59]\n",
      " [296 213 193 193]]\n",
      "[[297 211 195 195]]\n",
      "[[305 209 194 194]]\n",
      "[[308 208 193 193]\n",
      " [141 325  59  59]]\n",
      "[[310 207 193 193]\n",
      " [140 325  58  58]]\n",
      "[[140 325  59  59]\n",
      " [309 206 196 196]]\n",
      "[[141 326  57  57]\n",
      " [312 208 192 192]]\n",
      "[[141 325  59  59]\n",
      " [310 208 193 193]]\n",
      "[[298 209 191 191]]\n",
      "[[287 208 189 189]]\n",
      "[[283 208 190 190]]\n",
      "[[277 209 185 185]]\n",
      "[[275 208 188 188]]\n",
      "[[276 209 186 186]]\n",
      "[[277 211 183 183]]\n",
      "[[143 328  54  54]\n",
      " [279 211 183 183]]\n",
      "[[141 326  56  56]\n",
      " [277 211 184 184]]\n",
      "[[276 210 187 187]]\n",
      "[[277 211 185 185]\n",
      " [141 325  57  57]]\n",
      "[[140 326  57  57]\n",
      " [275 210 188 188]]\n",
      "[[141 325  58  58]\n",
      " [276 210 188 188]]\n",
      "[[275 210 188 188]]\n",
      "[[275 209 189 189]]\n",
      "[[142 326  56  56]\n",
      " [277 210 185 185]]\n",
      "[[141 326  58  58]\n",
      " [276 211 188 188]]\n",
      "[[277 212 187 187]]\n",
      "[[276 211 188 188]\n",
      " [137 323  64  64]]\n",
      "[[140 326  58  58]\n",
      " [277 212 188 188]]\n",
      "[[138 325  61  61]\n",
      " [277 212 187 187]]\n",
      "[[275 213 191 191]]\n",
      "[[275 213 192 192]]\n",
      "[[138 325  62  62]\n",
      " [276 214 191 191]]\n",
      "[[141 325  59  59]\n",
      " [275 214 191 191]]\n",
      "[[142 328  55  55]\n",
      " [275 214 192 192]]\n",
      "[[141 326  57  57]\n",
      " [275 214 193 193]]\n",
      "[[141 327  58  58]\n",
      " [275 215 191 191]]\n",
      "[[277 216 189 189]]\n",
      "[[276 214 192 192]]\n",
      "[[141 327  56  56]\n",
      " [278 215 191 191]]\n",
      "[[276 214 194 194]\n",
      " [141 326  58  58]]\n",
      "[[276 213 194 194]]\n",
      "[[140 326  58  58]\n",
      " [276 215 192 192]]\n",
      "[[141 325  59  59]\n",
      " [277 214 193 193]]\n",
      "[[277 214 193 193]]\n",
      "[[276 213 193 193]]\n",
      "[[139 325  60  60]\n",
      " [278 215 190 190]]\n",
      "[[275 213 196 196]]\n",
      "[[140 326  58  58]\n",
      " [276 214 194 194]]\n",
      "[[141 325  58  58]\n",
      " [275 213 195 195]]\n",
      "[[139 324  60  60]\n",
      " [277 215 192 192]]\n",
      "[[142 327  55  55]\n",
      " [276 213 195 195]]\n",
      "[[275 212 196 196]]\n",
      "[[276 213 195 195]]\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if ret==False:\n",
    "        break\n",
    "    img_detect=face_detection(frame)\n",
    "    cv2.imshow('realtime face detection',img_detect)\n",
    "    if cv2.waitKey(1)==ord('a'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7f7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
